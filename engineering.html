<!DOCTYPE HTML>

<html>
	<head>
		<title>BO859545</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="stylesheet" href="assets/css/sec.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>

		<style>
		

		</style>
		
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo"><strong>bo</strong> <span>859545</span></a>
						<nav>
							<a href="#menu">Menu</a>
						</nav>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li><a href="engineering.html">Engineering</a></li>
							<li><a href="reporting.html">Reporting</a></li>
							<li><a href="python.html">Programming</a></li>
							<li><a href="visualization.html">Visualization</a></li>
							<li><a href="ml.html">Machine Learning</a></li>
							<li><a href="big-data.html">Big Data</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main" class="alt">

						<!-- One -->
							<section id="one" style="background-color: white;">
								<div class="inner">
									<header class="major" style="margin: 0 auto;">
										 
										<!-- <nav id="sub-menu">
											<ul class="tertiary-nav" style="margin: auto 0;">
												<li><a href="engineering.html">Airflow</a></li>
												<li><a href="dagster.html">Dagster</a></li>
												<li><a href="template.html">AWS Glue</a></li>
												<li><a href="template.html">Azure Data Factory</a></li>
											</ul>
										</nav> -->
	
										<h2 style="color: #949494; text-align:center; padding-bottom: 0; font-weight: 500;" id="content">Building Data Pipeline</h2>
										<h4 style="color: #545454; text-align:center; margin-bottom: 0; font-weight: 500;" id="content">A modular data pipeline for a retail company.</h4>
										
									</header>

									<p style="color: #545454; width: 70%; margin: 20px auto; text-align: justify; font-size: 19px;">I'll leverage a combination of <span class="highlight">Python</span> for writing elt/etl scripts, <span class="highlight">Apache Airflow</span> for orchestration, <span class="highlight">BigQuery</span>, <span class="highlight">Snowflake</span>, <span class="highlight">AWS Redshift</span> for storage, <span class="highlight">dbt</span> for transformation & <span class="highlight">Amazon Managed Workflow for Apache Airiflow</span> to efficiently move data from a <span class="highlight">PostgreSQL</span> database to BigQuery for analytical processing.<br>
									</p>

									<!-- Content -->
									<!-- Where is the data? -->
									<h5 class="heading_five" style="margin-bottom: 2rem;">Where is the Data? <br><span style="color: #077ae6;">PostgreSQL Database</span></h5>
									<a href="images/postgresql.png" target="_blank"><img class="image" src="images/postgresql.png"/></a>

									<!-- Where do we consolidate the data? -->
									<h5 class="heading_five" style="margin-bottom: 2rem;">Where do we consolidate the data?<br><span style="color: #077ae6;">Google BigQuery</span></h5>
									<a href="images/target_bigquery.png" target="_blank"><img class="image" src="images/target_bigquery.png"/></a>

									<!-- Python Classes -->
									<h4 class="heading_five">Pipeline Design</h4>
									<p style="color: #545454; width: 70%; margin: 20px auto; text-align: justify; font-size: 19px;">I'll be using python classes to break the project components into manageable tasks. Python classes can significantly improve code organization, reusability, and scalability. It also ensures separation of concerns and making it easier to scale the ETL/ELT processes, debug issues, and onboard new team members. See figure below: file structure</p>
									<!-- <a href="images/vscode.png" target="_blank"><img class="image" style="margin-bottom: 5rem; margin-top: 3rem;" src="images/vscode.png"/></a> -->
									<a href="images/structure_i.png" target="_blank"><img class="image" style="height: 446px; width: 915px;" src="images/structure_i.png"/></a>

									<!-- Create & set user permissions in PostgreSQL -->
									<h5 class="heading_five">Create & set user permissions in PostgreSQL</h5>
									<pre class="py-code">
										<code style="margin: 0; padding: 0;">
		<span class="code-comment">1. Connect to PostgreSQL</span>
		$ sudo -u postgres psql
		<span class="code-comment">2. Create ETL/ELT User</span>
		$ CREATE USER etl_b085954 WITH PASSWORD 'BO@859545';
		<span class="code-comment">3. Grant Permissions</span>
		$ GRANT USAGE ON SCHEMA operations TO etl_b085954;
		$ GRANT SELECT ON ALL TABLES IN SCHEMA operations TO etl_b085954;
										</code>
									</pre>
									<a href="images/terminal_1.png" target="_blank"><img class="image" src="images/terminal_1.png"/></a>
									
									<!-- configuration/ -->
									<h5 class="heading_five">config.yaml</h5>
									<p class="paragraph">yaml configuration file for PostgreSQL, BigQuery connections, logging, & other settings.</p>
									<pre class="py-code">
										<code style="margin: 0; padding: 0;">
		<span class="code-func">postgres:</span>
			type: <span class="code-text">"postgresql"</span>
			host: <span class="code-text">"localhost"</span>
			port: <span class="brown-highlight">5432</span>
			database: <span class="code-text">"postgres"</span>
			user: <span class="code-text">"b085954"</span>
			password: <span class="code-text">"@Brian"</span>
			query: <span class="code-text">"SELECT * FROM sales"</span>

		<span class="code-func">bigquery:</span>
			project_id: <spam class="code-text">"adventureworks-431609"</spam>
			dataset_id: <span class="code-text">"adw"</span>
			table_id: <span class="code-text">"your_table"</span> 
			credentials_json: <span class="code-text">"path/to/your/credentials.json"</span>

		<span class="code-func">logging:</span>
			level: <span class="code-text">"INFO"</span>
			format: <span class="brown-highlight">"%(asctime)s - %(name)s - %(levelname)s - %(message)s"</span>
			file: <span class="code-text">"pipeline.log"</span>
			filemode: <span class="code-text">"a"</span>
										</code>
									</pre>
									<a href="images/vscode_config.yaml.png" target="_blank"><img class="image" src="images/vscode_config.yaml.png"/></a>

									<!-- requirements.txt/ -->
									<h5 class="heading_five">requirements.txt</h5>
									<p class="paragraph">list of dependencies & version to be installed</p>
									<pre class="py-code">
										<code style="margin: 0; padding: 0;">
		pandas => 2.2.3 
		requests
		sqlalchemy ==  2.0.36
		logging
		pyyaml
		os
		google-cloud-bigquery
										</code>
									</pre>

									<!-- Installing requirenet.txt -->
									<pre class="py-code">
										<code style="margin: 0; padding: 0;">
		<span class="code-comment">Installing requirements.txt</span> 
		$ pip install -r requirements.txt
										</code>
									</pre>

									<!-- extract/postresql.py -->
									<h5 class="heading_five">extract/postresql.py</h5>
									<p class="paragraph">.py script handles extraction from PostgreSQL database</p>
									<pre class="py-code">
										<code style="margin: 0; padding: 0;">
	<span class="py-method">from</span> sqlalchemy <span class="py-method">import</span> create_engine
	<span class="py-method">import</span> pandas<span class="py-method"> as</span> pd

	<span class="code-func">class</span> <span class="brown-highlight">PostgreSQL</span>:

		def __init__(self, config, logging):
			self.config = config
			self.logging = logging

		<span class="code-func">def</span> <span class="brown-highlight">extract</span></span>(<span class="code-func">self</span>) -> <span class="py-method">pd.DataFrame:</span>
			<span class="code-text">
			"""
			:extracts data from a PostgreSQL database.
			:param file_path: Path to the YAML configuration file
			:return: pandas DataFrame
			:raises ExceptionError: If the extraction fails
			"""</span> 

			db_config = <span class="py-method">self</span>.config[<span class="code-text">'postgres'</span>]
			<span class="py-method">try:</span> 
				engine_url =
					f<span class="code-text">"{db_config['type']}://{db_config['user']}:
					{db_config['password']}@"
					{db_config['host']}:
					{db_config['port']}/{db_config['database']}"
				</span> 
				engine = create_engine(engine_url)
				<span class="py-method">self</span>.logger.info(<span class="code-text">"Connecting to PostgreSQL database...</span>")
				<span class="code-func">with</span> engine.connect() as connection:
					<span class="py-method">self</span>.logger.info(<span class="code-text">"Executing query ..."</span>)
					df = pd.read_sql(db_config[<span class="code-text">'query'</span>], connection)
				<span class="py-method">self</span>.logger.info(f<span class="code-text">"Extracted</span> {len(df)} <span class="code-text">records from PostgreSQL database."</span>)
				<span class="py-method">return</span> df
			<span class="py-method">except</span> Exception as <span class="py-method">e:</span> 
				<span class="py-method">self</span>.logger.error(f<span class="code-text">"PostgreSQL extraction failed: {e}"</span> )
				<span class="py-method">raise</span>
										</code>
									</pre>

									<!-- utils/config_loader -->
									<h5 class="heading_five">utils/config_loader.py</h5>
									<p class="paragraph">.py script loads configurations from config.yaml file</p>
									<pre class="py-code">
										<code style="margin: 0; padding: 0;">
		<span class="py-method">import</span>  yaml

		<span class="code-func">class</span> <span class="brown-highlight">ConfigLoader:</span>
			<span class="code-func">def</span> <span class="brown-highlight">__init__</span> (<span class="py-method">self</span> , config_path=<span class="code-text">'config.yaml'</span>) -> <span class="py-method"> Dict:</span>
				<span class="py-method">self</span>.config_path = config_path
				<span class="py-method">self</span>.config = <span class="py-method">self</span>.load_config()

			<span class="code-func">def</span> <span class="brown-highlight">load_config</span>(<span class="py-method">self</span>) -> <span class="py-method">None:</span>
			<span class="code-text">
			"""
			:loads configuration from a YAML file.
			:param file_path: Path to the YAML configuration file
			:return: Configuration dictionary
			:raises FileNotFoundError: If the configuration file is not found
			:raises yaml.YAMLError: If there's an issue parsing the YAML file
			"""
		</span>
				<span class="py-method">if</span> <span class="code-func">not</span> os.path.exists(self.config_path):
					<span class="py-method">raise</span> FileNotFoundError(
						f<span class="code-text">"Configuration file '{config_path}' not found."</span>)

				<span class="py-method">with</span> open(<span class="py-method">self</span>.config_path, <span class="code-text">'r'</span>) as file:
					<span class="py-method">try:</span>
						config = yaml.safe_load(file)
					<span class="py-method">except:</span> yaml.YAMLError as exc:
						<span class="py-method">raise:</span> Exception(f<span class="code-text">"Error parsing YAML file: {exc}"</span>)
				<span class="py-method">return</span> config
										</code>
									</pre>

										<!-- utils/logging -->
										<h5 class="heading_five">utils/logging.py</h5>
										<p class="paragraph">.py manages logging</p>
										<pre class="py-code">
											<code style="margin: 0; padding: 0;">
	<span class="py-method">import</span> logging

	<span class="code-func">class</span> Logger:
		<span class="code-func">def</span> <span class="brown-highlight">__init__</span> (<span class="py-method">self</span>, config):
			<span class="py-method">self</span>.logger = logging.getLogger(<spam class="code-text">'bo859545_pipeline'</spam>)
			<span class="py-method">self</span>.logger.setLevel(
				getattr(logging, config[<span class="code-text">'logging'</span>][<span class="code-text">'level'</span>].upper(),
				logging.INFO))
	
			<span class="code-comment"># Prevent adding multiple handlers in interactive environments</span>
			<span class="py-method">if</span> <span class="code-func">not</span> self.logger.handlers:
				# File handler
				fh = logging.FileHandler(config[<span class="code-text">'logging'</span>][<span class="code-text">'file'</span>])
				fh.setLevel(getattr(logging,
				config['logging']['level'].upper(), logging.INFO))
				
				# Console handler
				ch = logging.StreamHandler()
				ch.setLevel(getattr(logging,
				config['logging']['level'].upper(), logging.INFO))
				
				# Formatter
				formatter = logging.Formatter(
					'%(asctime)s - %(name)s - %(levelname)s - %(message)s'
					)
				fh.setFormatter(formatter)
				ch.setFormatter(formatter)
				
				# Add handlers
				self.logger.addHandler(fh)
				self.logger.addHandler(ch)
	
		<span class="code-func">def</span> <span class="brown-highlight">get_logger</span>(self):
			<span class="py-method">return</span> self.logger									
											</code>
										</pre>

										<!-- piepline -->
										<h5 class="heading_five">/pipeline.py</h5>
										<p class="paragraph">.py script ochestrates (order of execution) of the entire pipeline</p>
										<pre class="py-code">
											<code style="margin: 0; padding: 0;">
		<span class="py-method">from</span> extract.postgres <span class="py-method">import</span> PostgreSQL
		<span class="py-method">import</span> pandas <span class="py-method">as</span> pd

		<span class="code-func">class</span> Pipeline:
			<span class="code-func">def</span> <span class="brown-highlight">__init__</span> (<span class="py-method">self</span>, config, logger):
				<span class="py-method">self</span>.config = config
				<span class="py-method">self</span>.logger = logger
				<span class="py-method">self</span>.extractors = <span class="py-method">self</span>.initialize_extractors()

			<span class="code-func">def</span> extractor(<span class="py-method">self</span>):
				extractor = PostgreSQL(<span class="code-func">self</span>.config, <span class="code-func">self</span>.logger)
				<span class="py-method">try:</span>
					df = extractor.extract()
					<span class="code-func">return</span> df

			<span class="code-func">def</span> loader(<span class="py-method">self</span>):
				<span class="py-method">pass</span>
											</code>
										</pre>

										<!-- main -->
										<h5 class="heading_five">/main.py</h5>
										<p class="paragraph">entry point to run the entire elt/etl pipeline</p>
										<pre class="py-code">
											<code style="margin: 0; padding: 0;">
		<span class="py-method">from</span> utils.config_loader <span class="py-method">import</span> ConfigLoader
		<span class="py-method">from</span> utils.logger <span class="py-method">import</span> Logger
		<span class="py-method">from</span> pipeline.pipeline <span class="py-method">import</span> Pipeline
		
		<span class="code-func">def</span> main():
				<span class="code-comment"># Load configuration</span>
				config_loader = ConfigLoader()
				config = config_loader.get_config()
		
				<span class="code-comment"># Setup logger</span>
				logger_instance = Logger(config)
				logger = logger_instance.get_logger()
				logger.info(<span class="code-text">"Starting the data extraction process..."</span>)
		
				<span class="code-comment"># Initialize and run the pipeline</span>
				pipeline = Pipeline(config, logger)
				pipeline.run()
		
		<span class="py-method">if</span> <span class="brown-highlight">__name__</span>  ==  <span class="code-func">"__main__":</span>
				main()
									</code>					
								</pre>

									<h4 style="color: #3f3f3f; text-align:center; margin-bottom: 0; font-weight: 500;" id="content">Apache Airflow - Set Up</h4>
									<!-- <p style="color: #545454; width: 70%; margin: 50px auto; text-align: justify; font-size: 19px;">I'll proceed to install a local instance of Apache Airflow on a Linux machine. Once Apache Airflow Webserver and Scheduler are up and running, add airflow dependencies to requirements.txt for installation.</p>
											 -->
										<pre class="py-code">
											<code style="margin: 0; padding: 0;">
		<span class="code-comment"># Apache Airflow - Local Set-Up</span>
		$ python3 -m venv airflow-env <span class="code-comment"> # create virtual environment</span>
		$ source airflow-env/bin/activate <span class="code-comment"> # activate virtual environment</span>
		$ export AIRFLOW_HOME=~/airflow
		$ pip install apache-airflow
		$ airflow db init
		$ airflow webserver -p 8080 <span class="code-comment">#launch webserver</span>
		$ airflow sheduler <span class="code-comment">#launch scheduler</span>
												</code>
											</pre>

									<h3 style="color: #3f3f3f; text-align:center; margin-bottom: 0; font-weight: 300;" id="content">Airflow Weberver UI</h3>
									<a href="images/airflow.png" target="_blank"><img class="image" src="images/airflow.png" alt="" /></a>

									
									<!-- ORCHESTRATION IN AIRFLOW -->
									<h5 class="heading_five">Orchestration - Apache Airflow Workflow</h5>
									<p class="paragraph">Airflow has its own directory structure, primarily the dags folder where DAG definitions reside. To integrate the existing pipeline, I'll adjust the project structure and move the pipeline.py to dag folder.</p>
									<h5 class="heading_five">/dag/pipeline.py</h5>
									<pre class="py-code">
										<code style="margin: 0; padding: 0;">
		<span class="code-comment"># defining a dag - Direct Acyclic Graph</span>

		<span class="py-method">from</span> datetime <span class="py-method">import</span> datetime, timedelta
		<span class="py-method">from</span> airflow <span class="py-method">import</span> DAG
		<span class="py-method">from</span> airflow.operators.python_operator <span class="py-method">import</span> PythonOperator
		<span class="py-method">from</span> extract.postgresql <span class="py-method">import</span> PostgreSQL
		<span class="py-method">from</span> utils.config_loader <span class="py-method">import</span> ConfigLoader
		<span class="py-method">from</span> utils.logging <span class="py-method">import</span> Logger
		<span class="py-method">import</span> pandas <span class="py-method">as</span> pd
		<span class="py-method">import</span> os

		args{
			<span class="code-text">”owner”</span> : <span class="code-text">BO859545</span> ,
			<span class="code-text">"retries"</span>: 1,
			<span class="code-text">"retry_delay"</span>:timedelta(minutes=5)
			}

		<span class="code-comment"># Define the DAG</span>

		<span class="py-method">with</span> DAG(
				<span class="code-text">'data_pipeline_dag'</span>,
				default_args=default_args,
				description=<span class="code-text">'Operations Department data pipeline'</span>,
				schedule_interval=timedelta(days=1),
				start_date=datetime(2024, 1, 1),
				catchup=False,
		) as dag:

		<span class="code-func">def</span> <span class="brown-highlight">load_config</span>(**kwargs):
			<span class="code-comment">"""Task to load configuration."""</span> 
			config = load_config()
			logger = get_logger(config)
			<span class="code-comment"># Push to XCom for other tasks</span>
			kwargs[<span class="code-text">'ti'</span>].xcom_push(key=<span class="code-text">'config'</span>, value=config)
			kwargs[<span class="code-text">'ti'</span>].xcom_push(key=<span class="code-text">'logger'</span>, value=logger)
			logger.info(<span class="code-text">"Configuration loaded and logger initialized."</span>)

		<span class="code-func">def</span> <span class="brown-highlight">postgresql</span>(**kwargs):
			<span class="code-comment">"""Task to extract data from the database."""</span>
			ti = kwargs[<span class="code-text">'ti'</span>]
			config = ti.xcom_pull(key=<span class="code-text">'config'</span> , task_ids=<span class="code-text">'load_configuration'</span>)
			logger = get_logger(config)
			return PostgreSQL(config, logger)

		<span class="code-comment"># Define tasks</span>
		load_config_task = PythonOperator(
				task_id=<span class="code-text">'load_config'</span>,
				python_callable=config_loader,
				provide_context=True,
		)

		extract_db_task = PythonOperator(
				task_id=<span class="code-text">'extract postgresql'</span>,
				python_callable=postgresql,
				provide_context=True,
		)
										</code>
									</pre>

									<h5 class="heading_five">Running Pipeline</h5>
									<a href="images/VIII.png" target="_blank"><img class="image" src="images/orchestration_airflow.png" alt=""/></a>
									<a href="images/XII.png" target="_blank"><img class="image" src="images/XII.png" alt="" /></a>
									<a href="images/load.png" target="_blank"><img class="image" src="images/load.png" alt="" /></a>
								
					</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>